{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "767f3626",
   "metadata": {},
   "source": [
    "# NLP Assignment Exercises\n",
    "This notebook contains solutions to all five exercises from the NLP preprocessing course.\n",
    "\n",
    "## Exercises:\n",
    "1. Compare performances: CountVectorizer vs TfidfVectorizer vs Word2Vec averaged embeddings on a 10k-sample dataset\n",
    "2. Try ngram_range=(1,3) and observe overfitting/feature explosion\n",
    "3. Use GridSearchCV to tune C for Logistic Regression and alpha for MultinomialNB\n",
    "4. Create an inference API using FastAPI that loads best_text_pipeline.joblib and exposes POST /predict\n",
    "5. (Advanced) Fine-tune a small transformer (e.g., DistilBERT) for sentiment classification using Hugging Face transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe523aa1",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6d153c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q scikit-learn pandas numpy matplotlib seaborn gensim datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6bbe04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set plot style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1550c1b3",
   "metadata": {},
   "source": [
    "## Load Dataset (10k samples)\n",
    "We'll use the IMDb movie review dataset for sentiment classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "438d9fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading IMDb dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (10000, 2)\n",
      "\n",
      "Label distribution:\n",
      "label\n",
      "0    5004\n",
      "1    4996\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample review:\n",
      "There is no relation at all between Fortier and Profiler but the fact that both are police series about violent crimes. Profiler looks crispy, Fortier looks classic. Profiler plots are quite simple. F...\n"
     ]
    }
   ],
   "source": [
    "# Load IMDb dataset\n",
    "print(\"Loading IMDb dataset...\")\n",
    "dataset = load_dataset(\"imdb\", split=\"train\")\n",
    "\n",
    "# Take 10k samples\n",
    "dataset = dataset.shuffle(seed=42).select(range(10000))\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'text': dataset['text'],\n",
    "    'label': dataset['label']\n",
    "})\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nLabel distribution:\\n{df['label'].value_counts()}\")\n",
    "print(f\"\\nSample review:\\n{df['text'].iloc[0][:200]}...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
